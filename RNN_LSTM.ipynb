{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "g1GznJhObXPk",
        "Gr9BxL8zeBfv"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francescoscalera99/AML_labs/blob/main/RNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf3z5SqWZ91b"
      },
      "source": [
        "# Torch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbtEmI1AiTkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edafc048-9fab-4046-c1d3-a88b8bb4fdcb"
      },
      "source": [
        "#!pip3 install 'torch==1.3.1'\n",
        "#!pip3 install 'torchvision==0.5.0'\n",
        "#!pip3 install 'Pillow-SIMD'\n",
        "#!pip3 install 'tqdm'\n",
        "!pip3 install \"colorama\"\n",
        "\n",
        "import torch\n",
        "\n",
        "#use GPU if available \n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #'cpu' # 'cuda' or 'cpu'\n",
        "print(DEVICE)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.6)\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czjvnq3FjBmh"
      },
      "source": [
        "# Download Dataset GTEA61"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGOhXMNqjMed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81871477-32f9-427a-ff67-7b130aac4297"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "import sys, os\n",
        "           \n",
        "#1YKfdhB9Xxh4pmND1V3gcm3Gyjc8v8idq\n",
        "if not os.path.isfile('/content/GTEA61.zip'):\n",
        "  #!gdown --id 1Z5RWA8yKIy0PvxMlScV-aAz22ITtivfk # 3-5 min\n",
        "  !cp \"/content/drive/MyDrive/GTEA61.zip\" \"/content\"\n",
        "  !jar xvf  \"/content/GTEA61.zip\"\n",
        "\n",
        "if not os.path.isdir('/content/GTEA61'):\n",
        "  print(\"Dataset doesn't exist\")\n",
        "\n",
        "#Weights\n",
        "if not os.path.isfile(\"/content/drive/best_model_state_dict_rgb_split2.pth\"):\n",
        "  !gdown --id 1B7Xh6hQ9Py8fmL-pjmLzlCent6dnuex5 # 3-5 min\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1B7Xh6hQ9Py8fmL-pjmLzlCent6dnuex5\n",
            "To: /content/best_model_state_dict_rgb_split2.pth\n",
            "100% 163M/163M [00:00<00:00, 266MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk0rtAlnSlDF"
      },
      "source": [
        "\n",
        "# Download Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8xcWfReaSd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95615851-f1f7-48f1-d13e-ad5d8ce0a883"
      },
      "source": [
        "!git clone \"https://github.com/plana93/Homework_AIML.git\" \n",
        "#!rm -r \"/content/Homework_AIML\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Homework_AIML' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiwWzjzSio-h"
      },
      "source": [
        "\n",
        "\n",
        "# Import Code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl6fSd3MXofW"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.backends import cudnn\n",
        "import torchvision\n",
        "from colorama import init\n",
        "from colorama import Fore, Back, Style\n",
        "\n",
        "from torchvision.models import resnet34\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/Homework_AIML/\")\n",
        "import Homework_AIML\n",
        "from Homework_AIML import *\n",
        "\n",
        "from gtea_dataset import GTEA61, GTEA61_flow, GTEA61_2Stream\n",
        "from spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\n",
        "                                RandomHorizontalFlip)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1GznJhObXPk"
      },
      "source": [
        "#**Learning without Temporal information** (avgpool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy4KrHClbAmC"
      },
      "source": [
        "#MAIN PARAMs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-tz9mHPbCYW"
      },
      "source": [
        "homework_step = 1\n",
        "#homework_step = 0 #--> Learning with Temporal information (LSTM)\n",
        "#homework_step = 1 #--> Learning with Temporal information (LSTM)\n",
        "#homework_step = 2 #--> Learning with Spatio-Temporal information (ConvLSTM)\n",
        "\n",
        "\n",
        "\n",
        "DATA_DIR = '/content/GTEA61/' #path dataset\n",
        "model_folder = '/content/saved_models/' + \"/\" + \"homework_step\"+ str(homework_step) + \"/\" #path to save model \n",
        "if not os.path.isdir(model_folder):\n",
        "    os.makedirs(model_folder)\n",
        "\n",
        "\n",
        "# All this param can be change!\n",
        "\n",
        "NUM_CLASSES = 61     \n",
        "BATCH_SIZE = 64 \n",
        "LR = 0.001            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 4e-5  # Regularization, you can keep this at the default\n",
        "NUM_EPOCHS = 200     # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = [25, 75, 150] # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "MEM_SIZE = 512       # Dim of internal state of LSTM or ConvLSTM\n",
        "SEQ_LEN = 3          # Num Frames\n",
        "\n",
        "# this dictionary is needed for the logger class\n",
        "parameters = {'DEVICE':DEVICE, 'NUM_CLASSES':NUM_CLASSES, 'BATCH_SIZE':BATCH_SIZE,\n",
        "             'LR':LR, 'MOMENTUM':MOMENTUM, 'WEIGHT_DECAY':WEIGHT_DECAY, 'NUM_EPOCHS':NUM_EPOCHS,\n",
        "             'STEP_SIZE':STEP_SIZE, 'GAMMA':GAMMA, 'MEM_SIZE':MEM_SIZE, 'SEQ_LEN':SEQ_LEN}"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPwkOR8taVdN"
      },
      "source": [
        "#Dataloaders & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT_Gy79SgBLq"
      },
      "source": [
        "# Normalize\n",
        "normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "spatial_transform = Compose([Scale(256), RandomHorizontalFlip(), MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224),\n",
        "                             ToTensor(), normalize])\n",
        "spatial_transform_val = Compose([Scale(256), CenterCrop(224), ToTensor(), normalize])\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T69vfGGhjKa_",
        "outputId": "f184f061-875d-45a2-adef-2333306c92ab"
      },
      "source": [
        "# Prepare Pytorch train/test Datasets\n",
        "train_dataset = GTEA61(DATA_DIR, split='train', transform=spatial_transform, seq_len=SEQ_LEN)\n",
        "test_dataset = GTEA61(DATA_DIR, split='test', transform=spatial_transform_val, seq_len=SEQ_LEN)\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Train Dataset: {}'.format(len(train_dataset)))\n",
        "print('Test Dataset: {}'.format(len(test_dataset)))\n",
        "\n",
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['S1', 'S3', 'S4', 'S2']\n",
            "['S1', 'S3', 'S4', 'S2']\n",
            "Train Dataset: 341\n",
            "Test Dataset: 116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21wjiwvW-OPQ"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMWuE-4SHxoY"
      },
      "source": [
        "import torch\n",
        "import resnetMod\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "\n",
        "# LSTM\n",
        "class MyLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(MyLSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i_xx = nn.Linear(input_size, hidden_size)\n",
        "        self.i_hh = nn.Linear(hidden_size, hidden_size,bias=False)\n",
        "\n",
        "        self.f_xx = nn.Linear(input_size, hidden_size)\n",
        "        self.f_hh = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "\n",
        "        self.g_xx = nn.Linear(input_size, hidden_size)\n",
        "        self.g_hh = nn.Linear(hidden_size, hidden_size,bias=False)\n",
        "\n",
        "        self.o_xx = nn.Linear(input_size, hidden_size)\n",
        "        self.o_hh = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.i_xx.weight)\n",
        "        torch.nn.init.constant_(self.i_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.i_hh.weight)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.f_xx.weight)\n",
        "        torch.nn.init.constant_(self.f_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.f_hh.weight)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.g_xx.weight)\n",
        "        torch.nn.init.constant_(self.g_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.g_hh.weight)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.o_xx.weight)\n",
        "        torch.nn.init.constant_(self.o_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.o_hh.weight)\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        if state is None:\n",
        "            state = (Variable(torch.randn(x.size(0), x.size(1)).cuda()),\n",
        "                     Variable(torch.randn(x.size(0), x.size(1)).cuda()))\n",
        "        \n",
        "        i = torch.sigmoid(self.i_xx(x)+self.i_hh(state[1]))\n",
        "        f = torch.sigmoid(self.f_xx(x)+self.f_hh(state[1]))\n",
        "        o = torch.sigmoid(self.o_xx(x)+self.o_hh(state[1]))\n",
        "        g = torch.tanh(self.g_xx(x)+self.g_hh(state[1]))\n",
        "\n",
        "        c_t = f * state[0] + i * g\n",
        "        h_t = o * torch.tanh(c_t)\n",
        "\n",
        "        return  c_t, h_t\n",
        "\n",
        "\n",
        "#ConvLSTM\n",
        "class MyConvLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, kernel_size=3, stride=1, padding=1):\n",
        "        super(MyConvLSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.conv_i_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv_i_hh = nn.Conv2d(hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                   bias=False)\n",
        "\n",
        "        self.conv_f_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv_f_hh = nn.Conv2d(hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                   bias=False)\n",
        "\n",
        "        self.conv_c_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv_c_hh = nn.Conv2d(hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                   bias=False)\n",
        "\n",
        "        self.conv_o_xx = nn.Conv2d(input_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.conv_o_hh = nn.Conv2d(hidden_size, hidden_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                   bias=False)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.conv_i_xx.weight)\n",
        "        torch.nn.init.constant_(self.conv_i_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.conv_i_hh.weight)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.conv_f_xx.weight)\n",
        "        torch.nn.init.constant_(self.conv_f_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.conv_f_hh.weight)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.conv_c_xx.weight)\n",
        "        torch.nn.init.constant_(self.conv_c_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.conv_c_hh.weight)\n",
        "\n",
        "        torch.nn.init.xavier_normal_(self.conv_o_xx.weight)\n",
        "        torch.nn.init.constant_(self.conv_o_xx.bias, 0)\n",
        "        torch.nn.init.xavier_normal_(self.conv_o_hh.weight)\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        if state is None:\n",
        "            state = (Variable(torch.randn(x.size(0), x.size(1), x.size(2), x.size(3)).cuda()),\n",
        "                     Variable(torch.randn(x.size(0), x.size(1), x.size(2), x.size(3)).cuda()))\n",
        "        \n",
        "        i = torch.sigmoid(self.conv_i_xx(x)+self.conv_i_hh(state[1]))\n",
        "        f = torch.sigmoid(self.conv_f_xx(x)+self.conv_f_hh(state[1]))\n",
        "        o = torch.sigmoid(self.conv_o_xx(x)+self.conv_o_hh(state[1]))\n",
        "        g = torch.tanh(self.conv_c_xx(x)+self.conv_c_hh(state[1]))\n",
        "\n",
        "        c_t = f * state[0] + i * g\n",
        "        h_t = o * torch.tanh(c_t)\n",
        "\n",
        "        return  c_t, h_t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Network \n",
        "class ourModel(nn.Module):\n",
        "    def __init__(self, num_classes=61, mem_size=512, homework_step = 0 , DEVICE=\"\"):\n",
        "        super(ourModel, self).__init__()\n",
        "        self.DEVICE = DEVICE\n",
        "        self.num_classes = num_classes\n",
        "        self.resNet = resnetMod.resnet34(True, True)\n",
        "        self.mem_size = mem_size\n",
        "        self.weight_softmax = self.resNet.fc.weight\n",
        "        self.homework_step = homework_step\n",
        "        if self.homework_step == 1:\n",
        "          self.lstm_cell = MyLSTMCell(512, mem_size)\n",
        "        elif self.homework_step == 2:\n",
        "          self.lstm_cell = MyConvLSTMCell(512, mem_size)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(7)\n",
        "        self.dropout = nn.Dropout(0.7)\n",
        "        self.fc = nn.Linear(mem_size, self.num_classes)\n",
        "        self.classifier = nn.Sequential(self.dropout, self.fc)\n",
        "\n",
        "    def forward(self, inputVariable):\n",
        "        #Learning without Temporal information (mean)\n",
        "        if self.homework_step == 0:\n",
        "            video_level_features = torch.zeros((inputVariable.size(1), self.mem_size)).to(self.DEVICE)\n",
        "            for t in range(inputVariable.size(0)):\n",
        "                #spatial_frame_feat: (bs, 512, 7, 7)\n",
        "                _, spatial_frame_feat, _ = self.resNet(inputVariable[t])\n",
        "                #frames_feat: (bs, 512)\n",
        "                frame_feat = self.avgpool(spatial_frame_feat).view(spatial_frame_feat.size(0), -1)\n",
        "                video_level_features = video_level_features + frame_feat\n",
        "\n",
        "            video_level_features = video_level_features / inputVariable.size(0)\n",
        "            logits = self.classifier(video_level_features)\n",
        "            return logits, video_level_features\n",
        "\n",
        "        #Learning with Temporal information (LSTM)\n",
        "        elif self.homework_step == 1:\n",
        "            state = ( torch.zeros((inputVariable.size(1), self.mem_size)).to(self.DEVICE),\n",
        "                     torch.zeros((inputVariable.size(1), self.mem_size)).to(self.DEVICE) ) \n",
        "            for t in range(inputVariable.size(0)):\n",
        "                #spatial_frame_feat: (bs, 512, 7, 7)\n",
        "                _, spatial_frame_feat, _ = self.resNet(inputVariable[t])\n",
        "                #frames_feat: (bs, 512)\n",
        "                frame_feat = self.avgpool(spatial_frame_feat).view(state[1].size(0), -1)\n",
        "                state = self.lstm_cell(frame_feat, state)\n",
        "\n",
        "            video_level_features = state[1]\n",
        "            logits = self.classifier(video_level_features)\n",
        "            return logits, video_level_features\n",
        "\n",
        "        #Learning with Temporal information (ConvLSTM)\n",
        "        elif self.homework_step == 2:\n",
        "            state = (torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).to(self.DEVICE),\n",
        "                     torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).to(self.DEVICE))\n",
        "            for t in range(inputVariable.size(0)):\n",
        "                #spatial_frame_feat: (bs, 512, 7, 7)\n",
        "                _, spatial_frame_feat, _ = self.resNet(inputVariable[t])\n",
        "                state = self.lstm_cell(spatial_frame_feat, state)\n",
        "            video_level_features = self.avgpool(state[1]).view(state[1].size(0), -1)\n",
        "            logits = self.classifier(video_level_features)\n",
        "            return logits, video_level_features"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru8vllrMbgvL"
      },
      "source": [
        "#Build Model - Loss - Opt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZe-ZbEL7z3x"
      },
      "source": [
        "#CUDA_LAUNCH_BLOCKING=1\n",
        "validate = True\n",
        "\n",
        "model = ourModel(num_classes=NUM_CLASSES, mem_size=MEM_SIZE, homework_step=homework_step, DEVICE=DEVICE) #model\n",
        "\n",
        "#Train only the lstm cell and classifier\n",
        "model.train(False)\n",
        "for params in model.parameters():\n",
        "    params.requires_grad = False\n",
        "\n",
        "if homework_step > 0:\n",
        "    for params in model.lstm_cell.parameters():\n",
        "        params.requires_grad = True\n",
        "    model.lstm_cell.train(True)\n",
        "\n",
        "for params in model.classifier.parameters():\n",
        "    params.requires_grad = True\n",
        "model.classifier.train(True)\n",
        "\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "if homework_step == 2:\n",
        "  model.load_state_dict(torch.load(\"/content/best_model_state_dict_rgb_split2.pth\", map_location=torch.device('cpu')), strict=True)\n",
        "\n",
        "#Loss\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#Opt\n",
        "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer_fn = optim.Adam(trainable_params, lr=LR, weight_decay=WEIGHT_DECAY, eps=1e-4)\n",
        "#Scheduler\n",
        "optim_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=STEP_SIZE, gamma=GAMMA)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0MWgLingzhw"
      },
      "source": [
        "#Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-uE2A9eHmtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a333352e-5f9c-4d78-8b06-42cb25fcfec4"
      },
      "source": [
        "train_iter = 0\n",
        "val_iter = 0\n",
        "min_accuracy = 0\n",
        "\n",
        "trainSamples = len(train_dataset) - (len(train_dataset) % BATCH_SIZE)\n",
        "val_samples = len(test_dataset) \n",
        "iterPerEpoch = len(train_loader)\n",
        "val_steps = len(val_loader)\n",
        "cudnn.benchmark\n",
        "model_checkpoint = \"model\" #name\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    numCorrTrain = 0\n",
        "    \n",
        "    #blocks to train\n",
        "    if homework_step > 0:\n",
        "        model.lstm_cell.train(True)\n",
        "    model.classifier.train(True)\n",
        "    \n",
        "    \n",
        "    for i, (inputs, targets) in enumerate(train_loader):\n",
        "        train_iter += 1\n",
        "        optimizer_fn.zero_grad()\n",
        "        \n",
        "        # (BS, Frames, C, W, H) --> (Frames, BS, C, W, H)\n",
        "        inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "        labelVariable = targets.to(DEVICE)\n",
        "\n",
        "        # feeds in model\n",
        "        output_label, _ = model(inputVariable)\n",
        "        \n",
        "        # compute loss \n",
        "        loss = loss_fn(output_label, labelVariable)\n",
        "\n",
        "        # backward loss and optimizer step \n",
        "        loss.backward()\n",
        "        optimizer_fn.step()\n",
        "        \n",
        "        #compute the training accuracy \n",
        "        _, predicted = torch.max(output_label.data, 1)\n",
        "        numCorrTrain += torch.sum(predicted == labelVariable.data).data.item()\n",
        "        step_loss = loss.data.item()\n",
        "        epoch_loss += step_loss\n",
        "    \n",
        "    avg_loss = epoch_loss/iterPerEpoch\n",
        "    trainAccuracy = (numCorrTrain / trainSamples) * 100\n",
        "    #train_logger.add_epoch_data(epoch+1, trainAccuracy, avg_loss)\n",
        "    print(Fore.BLACK + 'Train: Epoch = {} | Loss = {:.3f} | Accuracy = {:.3f}'.format(epoch+1, avg_loss, trainAccuracy))\n",
        "    if validate:\n",
        "        if (epoch+1) % 1 == 0:\n",
        "            model.train(False)\n",
        "            val_loss_epoch = 0\n",
        "            numCorr = 0\n",
        "            for j, (inputs, targets) in enumerate(val_loader):\n",
        "                val_iter += 1\n",
        "                inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "                labelVariable = targets.to(DEVICE)\n",
        "                \n",
        "                output_label, _ = model(inputVariable)\n",
        "                val_loss = loss_fn(output_label, labelVariable)\n",
        "                val_loss_step = val_loss.data.item()\n",
        "                val_loss_epoch += val_loss_step\n",
        "                _, predicted = torch.max(output_label.data, 1)\n",
        "                numCorr += torch.sum(predicted == labelVariable.data).data.item()\n",
        "                #val_logger.add_step_data(val_iter, numCorr, val_loss_step)\n",
        "                \n",
        "            val_accuracy = (numCorr / val_samples) * 100\n",
        "            avg_val_loss = val_loss_epoch / val_steps\n",
        "\n",
        "            print(Fore.GREEN + 'Val: Epoch = {} | Loss {:.3f} | Accuracy = {:.3f}'.format(epoch + 1, avg_val_loss, val_accuracy))\n",
        "            if val_accuracy > min_accuracy:\n",
        "                print(\"[||| NEW BEST on val||||]\")\n",
        "                save_path_model = os.path.join(model_folder, model_checkpoint)\n",
        "                torch.save(model.state_dict(), save_path_model)\n",
        "                min_accuracy = val_accuracy\n",
        "    \n",
        "    optim_scheduler.step()\n",
        "\n",
        "print(Fore.CYAN + \"Best Acc --> \", min_accuracy)\n",
        "print(Fore.CYAN + \"Last Acc --> \", val_accuracy)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[30mTrain: Epoch = 1 | Loss = 4.142 | Accuracy = 3.125\n",
            "\u001b[32mVal: Epoch = 1 | Loss 3.940 | Accuracy = 5.172\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 2 | Loss = 3.983 | Accuracy = 6.250\n",
            "\u001b[32mVal: Epoch = 2 | Loss 3.905 | Accuracy = 6.034\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 3 | Loss = 3.918 | Accuracy = 5.938\n",
            "\u001b[32mVal: Epoch = 3 | Loss 3.876 | Accuracy = 7.759\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 4 | Loss = 3.943 | Accuracy = 6.562\n",
            "\u001b[32mVal: Epoch = 4 | Loss 3.845 | Accuracy = 7.759\n",
            "\u001b[30mTrain: Epoch = 5 | Loss = 3.923 | Accuracy = 6.562\n",
            "\u001b[32mVal: Epoch = 5 | Loss 3.824 | Accuracy = 9.483\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 6 | Loss = 3.868 | Accuracy = 7.187\n",
            "\u001b[32mVal: Epoch = 6 | Loss 3.799 | Accuracy = 7.759\n",
            "\u001b[30mTrain: Epoch = 7 | Loss = 3.890 | Accuracy = 5.938\n",
            "\u001b[32mVal: Epoch = 7 | Loss 3.776 | Accuracy = 7.759\n",
            "\u001b[30mTrain: Epoch = 8 | Loss = 3.777 | Accuracy = 11.875\n",
            "\u001b[32mVal: Epoch = 8 | Loss 3.712 | Accuracy = 9.483\n",
            "\u001b[30mTrain: Epoch = 9 | Loss = 3.726 | Accuracy = 12.188\n",
            "\u001b[32mVal: Epoch = 9 | Loss 3.678 | Accuracy = 9.483\n",
            "\u001b[30mTrain: Epoch = 10 | Loss = 3.730 | Accuracy = 13.125\n",
            "\u001b[32mVal: Epoch = 10 | Loss 3.636 | Accuracy = 12.931\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 11 | Loss = 3.604 | Accuracy = 14.375\n",
            "\u001b[32mVal: Epoch = 11 | Loss 3.552 | Accuracy = 15.517\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 12 | Loss = 3.623 | Accuracy = 12.500\n",
            "\u001b[32mVal: Epoch = 12 | Loss 3.533 | Accuracy = 13.793\n",
            "\u001b[30mTrain: Epoch = 13 | Loss = 3.555 | Accuracy = 12.500\n",
            "\u001b[32mVal: Epoch = 13 | Loss 3.465 | Accuracy = 11.207\n",
            "\u001b[30mTrain: Epoch = 14 | Loss = 3.477 | Accuracy = 13.438\n",
            "\u001b[32mVal: Epoch = 14 | Loss 3.396 | Accuracy = 17.241\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 15 | Loss = 3.416 | Accuracy = 16.562\n",
            "\u001b[32mVal: Epoch = 15 | Loss 3.316 | Accuracy = 18.966\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 16 | Loss = 3.284 | Accuracy = 18.438\n",
            "\u001b[32mVal: Epoch = 16 | Loss 3.376 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 17 | Loss = 3.340 | Accuracy = 15.937\n",
            "\u001b[32mVal: Epoch = 17 | Loss 3.225 | Accuracy = 19.828\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 18 | Loss = 3.316 | Accuracy = 19.062\n",
            "\u001b[32mVal: Epoch = 18 | Loss 3.259 | Accuracy = 18.103\n",
            "\u001b[30mTrain: Epoch = 19 | Loss = 3.266 | Accuracy = 17.188\n",
            "\u001b[32mVal: Epoch = 19 | Loss 3.179 | Accuracy = 18.966\n",
            "\u001b[30mTrain: Epoch = 20 | Loss = 3.207 | Accuracy = 17.188\n",
            "\u001b[32mVal: Epoch = 20 | Loss 3.214 | Accuracy = 19.828\n",
            "\u001b[30mTrain: Epoch = 21 | Loss = 3.139 | Accuracy = 20.000\n",
            "\u001b[32mVal: Epoch = 21 | Loss 3.115 | Accuracy = 24.138\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 22 | Loss = 3.116 | Accuracy = 20.938\n",
            "\u001b[32mVal: Epoch = 22 | Loss 3.129 | Accuracy = 18.966\n",
            "\u001b[30mTrain: Epoch = 23 | Loss = 3.013 | Accuracy = 22.500\n",
            "\u001b[32mVal: Epoch = 23 | Loss 3.040 | Accuracy = 20.690\n",
            "\u001b[30mTrain: Epoch = 24 | Loss = 3.086 | Accuracy = 23.125\n",
            "\u001b[32mVal: Epoch = 24 | Loss 3.111 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 25 | Loss = 2.921 | Accuracy = 25.938\n",
            "\u001b[32mVal: Epoch = 25 | Loss 2.992 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 26 | Loss = 2.999 | Accuracy = 24.062\n",
            "\u001b[32mVal: Epoch = 26 | Loss 2.963 | Accuracy = 25.862\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 27 | Loss = 2.930 | Accuracy = 26.875\n",
            "\u001b[32mVal: Epoch = 27 | Loss 2.953 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 28 | Loss = 2.875 | Accuracy = 26.875\n",
            "\u001b[32mVal: Epoch = 28 | Loss 2.965 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 29 | Loss = 2.810 | Accuracy = 27.500\n",
            "\u001b[32mVal: Epoch = 29 | Loss 2.953 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 30 | Loss = 2.842 | Accuracy = 25.625\n",
            "\u001b[32mVal: Epoch = 30 | Loss 2.926 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 31 | Loss = 2.907 | Accuracy = 24.375\n",
            "\u001b[32mVal: Epoch = 31 | Loss 2.900 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 32 | Loss = 2.814 | Accuracy = 24.688\n",
            "\u001b[32mVal: Epoch = 32 | Loss 2.891 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 33 | Loss = 2.799 | Accuracy = 27.500\n",
            "\u001b[32mVal: Epoch = 33 | Loss 2.877 | Accuracy = 24.138\n",
            "\u001b[30mTrain: Epoch = 34 | Loss = 2.699 | Accuracy = 27.500\n",
            "\u001b[32mVal: Epoch = 34 | Loss 2.852 | Accuracy = 24.138\n",
            "\u001b[30mTrain: Epoch = 35 | Loss = 2.851 | Accuracy = 27.187\n",
            "\u001b[32mVal: Epoch = 35 | Loss 2.847 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 36 | Loss = 2.797 | Accuracy = 25.312\n",
            "\u001b[32mVal: Epoch = 36 | Loss 2.860 | Accuracy = 21.552\n",
            "\u001b[30mTrain: Epoch = 37 | Loss = 2.763 | Accuracy = 24.688\n",
            "\u001b[32mVal: Epoch = 37 | Loss 2.865 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 38 | Loss = 2.791 | Accuracy = 24.062\n",
            "\u001b[32mVal: Epoch = 38 | Loss 2.855 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 39 | Loss = 2.734 | Accuracy = 24.375\n",
            "\u001b[32mVal: Epoch = 39 | Loss 2.842 | Accuracy = 24.138\n",
            "\u001b[30mTrain: Epoch = 40 | Loss = 2.719 | Accuracy = 29.688\n",
            "\u001b[32mVal: Epoch = 40 | Loss 2.830 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 41 | Loss = 2.755 | Accuracy = 30.312\n",
            "\u001b[32mVal: Epoch = 41 | Loss 2.848 | Accuracy = 24.138\n",
            "\u001b[30mTrain: Epoch = 42 | Loss = 2.688 | Accuracy = 26.562\n",
            "\u001b[32mVal: Epoch = 42 | Loss 2.847 | Accuracy = 22.414\n",
            "\u001b[30mTrain: Epoch = 43 | Loss = 2.740 | Accuracy = 29.375\n",
            "\u001b[32mVal: Epoch = 43 | Loss 2.809 | Accuracy = 24.138\n",
            "\u001b[30mTrain: Epoch = 44 | Loss = 2.693 | Accuracy = 30.000\n",
            "\u001b[32mVal: Epoch = 44 | Loss 2.780 | Accuracy = 25.862\n",
            "\u001b[30mTrain: Epoch = 45 | Loss = 2.698 | Accuracy = 29.063\n",
            "\u001b[32mVal: Epoch = 45 | Loss 2.772 | Accuracy = 27.586\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 46 | Loss = 2.727 | Accuracy = 26.250\n",
            "\u001b[32mVal: Epoch = 46 | Loss 2.789 | Accuracy = 24.138\n",
            "\u001b[30mTrain: Epoch = 47 | Loss = 2.625 | Accuracy = 30.000\n",
            "\u001b[32mVal: Epoch = 47 | Loss 2.805 | Accuracy = 25.000\n",
            "\u001b[30mTrain: Epoch = 48 | Loss = 2.641 | Accuracy = 30.625\n",
            "\u001b[32mVal: Epoch = 48 | Loss 2.820 | Accuracy = 25.000\n",
            "\u001b[30mTrain: Epoch = 49 | Loss = 2.752 | Accuracy = 24.688\n",
            "\u001b[32mVal: Epoch = 49 | Loss 2.843 | Accuracy = 25.000\n",
            "\u001b[30mTrain: Epoch = 50 | Loss = 2.647 | Accuracy = 30.312\n",
            "\u001b[32mVal: Epoch = 50 | Loss 2.822 | Accuracy = 25.862\n",
            "\u001b[30mTrain: Epoch = 51 | Loss = 2.685 | Accuracy = 30.000\n",
            "\u001b[32mVal: Epoch = 51 | Loss 2.776 | Accuracy = 25.000\n",
            "\u001b[30mTrain: Epoch = 52 | Loss = 2.680 | Accuracy = 29.375\n",
            "\u001b[32mVal: Epoch = 52 | Loss 2.746 | Accuracy = 25.862\n",
            "\u001b[30mTrain: Epoch = 53 | Loss = 2.658 | Accuracy = 28.125\n",
            "\u001b[32mVal: Epoch = 53 | Loss 2.752 | Accuracy = 25.000\n",
            "\u001b[30mTrain: Epoch = 54 | Loss = 2.604 | Accuracy = 31.562\n",
            "\u001b[32mVal: Epoch = 54 | Loss 2.766 | Accuracy = 25.000\n",
            "\u001b[30mTrain: Epoch = 55 | Loss = 2.622 | Accuracy = 29.375\n",
            "\u001b[32mVal: Epoch = 55 | Loss 2.765 | Accuracy = 24.138\n",
            "\u001b[30mTrain: Epoch = 56 | Loss = 2.649 | Accuracy = 28.438\n",
            "\u001b[32mVal: Epoch = 56 | Loss 2.752 | Accuracy = 25.000\n",
            "\u001b[30mTrain: Epoch = 57 | Loss = 2.623 | Accuracy = 34.062\n",
            "\u001b[32mVal: Epoch = 57 | Loss 2.755 | Accuracy = 25.000\n",
            "\u001b[30mTrain: Epoch = 58 | Loss = 2.589 | Accuracy = 33.125\n",
            "\u001b[32mVal: Epoch = 58 | Loss 2.785 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 59 | Loss = 2.656 | Accuracy = 30.312\n",
            "\u001b[32mVal: Epoch = 59 | Loss 2.786 | Accuracy = 23.276\n",
            "\u001b[30mTrain: Epoch = 60 | Loss = 2.593 | Accuracy = 31.562\n",
            "\u001b[32mVal: Epoch = 60 | Loss 2.753 | Accuracy = 25.862\n",
            "\u001b[30mTrain: Epoch = 61 | Loss = 2.605 | Accuracy = 31.875\n",
            "\u001b[32mVal: Epoch = 61 | Loss 2.730 | Accuracy = 25.862\n",
            "\u001b[30mTrain: Epoch = 62 | Loss = 2.647 | Accuracy = 28.125\n",
            "\u001b[32mVal: Epoch = 62 | Loss 2.742 | Accuracy = 25.000\n",
            "\u001b[30mTrain: Epoch = 63 | Loss = 2.588 | Accuracy = 32.188\n",
            "\u001b[32mVal: Epoch = 63 | Loss 2.742 | Accuracy = 25.000\n",
            "\u001b[30mTrain: Epoch = 64 | Loss = 2.554 | Accuracy = 31.875\n",
            "\u001b[32mVal: Epoch = 64 | Loss 2.741 | Accuracy = 25.000\n",
            "\u001b[30mTrain: Epoch = 65 | Loss = 2.628 | Accuracy = 30.000\n",
            "\u001b[32mVal: Epoch = 65 | Loss 2.733 | Accuracy = 25.000\n",
            "\u001b[30mTrain: Epoch = 66 | Loss = 2.532 | Accuracy = 33.438\n",
            "\u001b[32mVal: Epoch = 66 | Loss 2.725 | Accuracy = 25.862\n",
            "\u001b[30mTrain: Epoch = 67 | Loss = 2.629 | Accuracy = 31.562\n",
            "\u001b[32mVal: Epoch = 67 | Loss 2.713 | Accuracy = 26.724\n",
            "\u001b[30mTrain: Epoch = 68 | Loss = 2.550 | Accuracy = 32.500\n",
            "\u001b[32mVal: Epoch = 68 | Loss 2.716 | Accuracy = 25.862\n",
            "\u001b[30mTrain: Epoch = 69 | Loss = 2.608 | Accuracy = 29.375\n",
            "\u001b[32mVal: Epoch = 69 | Loss 2.733 | Accuracy = 25.862\n",
            "\u001b[30mTrain: Epoch = 70 | Loss = 2.574 | Accuracy = 32.500\n",
            "\u001b[32mVal: Epoch = 70 | Loss 2.716 | Accuracy = 26.724\n",
            "\u001b[30mTrain: Epoch = 71 | Loss = 2.651 | Accuracy = 28.438\n",
            "\u001b[32mVal: Epoch = 71 | Loss 2.706 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 72 | Loss = 2.528 | Accuracy = 34.688\n",
            "\u001b[32mVal: Epoch = 72 | Loss 2.715 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 73 | Loss = 2.554 | Accuracy = 33.750\n",
            "\u001b[32mVal: Epoch = 73 | Loss 2.716 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 74 | Loss = 2.557 | Accuracy = 31.562\n",
            "\u001b[32mVal: Epoch = 74 | Loss 2.697 | Accuracy = 26.724\n",
            "\u001b[30mTrain: Epoch = 75 | Loss = 2.588 | Accuracy = 29.688\n",
            "\u001b[32mVal: Epoch = 75 | Loss 2.693 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 76 | Loss = 2.551 | Accuracy = 32.188\n",
            "\u001b[32mVal: Epoch = 76 | Loss 2.692 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 77 | Loss = 2.581 | Accuracy = 30.625\n",
            "\u001b[32mVal: Epoch = 77 | Loss 2.692 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 78 | Loss = 2.495 | Accuracy = 30.625\n",
            "\u001b[32mVal: Epoch = 78 | Loss 2.693 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 79 | Loss = 2.520 | Accuracy = 35.312\n",
            "\u001b[32mVal: Epoch = 79 | Loss 2.694 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 80 | Loss = 2.522 | Accuracy = 34.688\n",
            "\u001b[32mVal: Epoch = 80 | Loss 2.697 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 81 | Loss = 2.525 | Accuracy = 34.375\n",
            "\u001b[32mVal: Epoch = 81 | Loss 2.701 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 82 | Loss = 2.558 | Accuracy = 35.000\n",
            "\u001b[32mVal: Epoch = 82 | Loss 2.703 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 83 | Loss = 2.561 | Accuracy = 31.875\n",
            "\u001b[32mVal: Epoch = 83 | Loss 2.703 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 84 | Loss = 2.598 | Accuracy = 26.562\n",
            "\u001b[32mVal: Epoch = 84 | Loss 2.703 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 85 | Loss = 2.417 | Accuracy = 35.938\n",
            "\u001b[32mVal: Epoch = 85 | Loss 2.703 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 86 | Loss = 2.559 | Accuracy = 31.875\n",
            "\u001b[32mVal: Epoch = 86 | Loss 2.702 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 87 | Loss = 2.480 | Accuracy = 33.750\n",
            "\u001b[32mVal: Epoch = 87 | Loss 2.701 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 88 | Loss = 2.521 | Accuracy = 36.875\n",
            "\u001b[32mVal: Epoch = 88 | Loss 2.700 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 89 | Loss = 2.534 | Accuracy = 32.500\n",
            "\u001b[32mVal: Epoch = 89 | Loss 2.699 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 90 | Loss = 2.556 | Accuracy = 29.688\n",
            "\u001b[32mVal: Epoch = 90 | Loss 2.701 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 91 | Loss = 2.556 | Accuracy = 30.938\n",
            "\u001b[32mVal: Epoch = 91 | Loss 2.702 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 92 | Loss = 2.553 | Accuracy = 35.000\n",
            "\u001b[32mVal: Epoch = 92 | Loss 2.702 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 93 | Loss = 2.554 | Accuracy = 31.562\n",
            "\u001b[32mVal: Epoch = 93 | Loss 2.702 | Accuracy = 28.448\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 94 | Loss = 2.477 | Accuracy = 35.938\n",
            "\u001b[32mVal: Epoch = 94 | Loss 2.701 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 95 | Loss = 2.587 | Accuracy = 29.063\n",
            "\u001b[32mVal: Epoch = 95 | Loss 2.700 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 96 | Loss = 2.582 | Accuracy = 31.875\n",
            "\u001b[32mVal: Epoch = 96 | Loss 2.698 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 97 | Loss = 2.520 | Accuracy = 33.750\n",
            "\u001b[32mVal: Epoch = 97 | Loss 2.699 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 98 | Loss = 2.558 | Accuracy = 30.938\n",
            "\u001b[32mVal: Epoch = 98 | Loss 2.699 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 99 | Loss = 2.540 | Accuracy = 29.688\n",
            "\u001b[32mVal: Epoch = 99 | Loss 2.695 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 100 | Loss = 2.460 | Accuracy = 35.312\n",
            "\u001b[32mVal: Epoch = 100 | Loss 2.690 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 101 | Loss = 2.535 | Accuracy = 32.188\n",
            "\u001b[32mVal: Epoch = 101 | Loss 2.688 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 102 | Loss = 2.512 | Accuracy = 35.312\n",
            "\u001b[32mVal: Epoch = 102 | Loss 2.687 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 103 | Loss = 2.504 | Accuracy = 35.312\n",
            "\u001b[32mVal: Epoch = 103 | Loss 2.689 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 104 | Loss = 2.512 | Accuracy = 34.062\n",
            "\u001b[32mVal: Epoch = 104 | Loss 2.691 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 105 | Loss = 2.501 | Accuracy = 34.375\n",
            "\u001b[32mVal: Epoch = 105 | Loss 2.691 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 106 | Loss = 2.497 | Accuracy = 33.750\n",
            "\u001b[32mVal: Epoch = 106 | Loss 2.690 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 107 | Loss = 2.543 | Accuracy = 30.000\n",
            "\u001b[32mVal: Epoch = 107 | Loss 2.689 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 108 | Loss = 2.551 | Accuracy = 29.063\n",
            "\u001b[32mVal: Epoch = 108 | Loss 2.688 | Accuracy = 29.310\n",
            "[||| NEW BEST on val||||]\n",
            "\u001b[30mTrain: Epoch = 109 | Loss = 2.564 | Accuracy = 28.438\n",
            "\u001b[32mVal: Epoch = 109 | Loss 2.688 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 110 | Loss = 2.548 | Accuracy = 32.188\n",
            "\u001b[32mVal: Epoch = 110 | Loss 2.689 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 111 | Loss = 2.427 | Accuracy = 34.375\n",
            "\u001b[32mVal: Epoch = 111 | Loss 2.687 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 112 | Loss = 2.525 | Accuracy = 31.250\n",
            "\u001b[32mVal: Epoch = 112 | Loss 2.686 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 113 | Loss = 2.543 | Accuracy = 34.688\n",
            "\u001b[32mVal: Epoch = 113 | Loss 2.686 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 114 | Loss = 2.600 | Accuracy = 29.688\n",
            "\u001b[32mVal: Epoch = 114 | Loss 2.687 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 115 | Loss = 2.429 | Accuracy = 36.562\n",
            "\u001b[32mVal: Epoch = 115 | Loss 2.690 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 116 | Loss = 2.459 | Accuracy = 35.000\n",
            "\u001b[32mVal: Epoch = 116 | Loss 2.692 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 117 | Loss = 2.542 | Accuracy = 30.938\n",
            "\u001b[32mVal: Epoch = 117 | Loss 2.692 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 118 | Loss = 2.419 | Accuracy = 34.688\n",
            "\u001b[32mVal: Epoch = 118 | Loss 2.692 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 119 | Loss = 2.474 | Accuracy = 35.938\n",
            "\u001b[32mVal: Epoch = 119 | Loss 2.692 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 120 | Loss = 2.560 | Accuracy = 30.625\n",
            "\u001b[32mVal: Epoch = 120 | Loss 2.691 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 121 | Loss = 2.452 | Accuracy = 32.188\n",
            "\u001b[32mVal: Epoch = 121 | Loss 2.690 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 122 | Loss = 2.663 | Accuracy = 32.188\n",
            "\u001b[32mVal: Epoch = 122 | Loss 2.689 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 123 | Loss = 2.473 | Accuracy = 32.188\n",
            "\u001b[32mVal: Epoch = 123 | Loss 2.689 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 124 | Loss = 2.512 | Accuracy = 34.062\n",
            "\u001b[32mVal: Epoch = 124 | Loss 2.690 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 125 | Loss = 2.418 | Accuracy = 34.062\n",
            "\u001b[32mVal: Epoch = 125 | Loss 2.690 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 126 | Loss = 2.506 | Accuracy = 35.625\n",
            "\u001b[32mVal: Epoch = 126 | Loss 2.692 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 127 | Loss = 2.597 | Accuracy = 30.312\n",
            "\u001b[32mVal: Epoch = 127 | Loss 2.692 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 128 | Loss = 2.477 | Accuracy = 30.625\n",
            "\u001b[32mVal: Epoch = 128 | Loss 2.692 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 129 | Loss = 2.461 | Accuracy = 34.062\n",
            "\u001b[32mVal: Epoch = 129 | Loss 2.689 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 130 | Loss = 2.506 | Accuracy = 32.188\n",
            "\u001b[32mVal: Epoch = 130 | Loss 2.685 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 131 | Loss = 2.373 | Accuracy = 38.125\n",
            "\u001b[32mVal: Epoch = 131 | Loss 2.682 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 132 | Loss = 2.477 | Accuracy = 36.250\n",
            "\u001b[32mVal: Epoch = 132 | Loss 2.679 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 133 | Loss = 2.497 | Accuracy = 33.750\n",
            "\u001b[32mVal: Epoch = 133 | Loss 2.678 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 134 | Loss = 2.503 | Accuracy = 33.438\n",
            "\u001b[32mVal: Epoch = 134 | Loss 2.679 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 135 | Loss = 2.484 | Accuracy = 36.250\n",
            "\u001b[32mVal: Epoch = 135 | Loss 2.679 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 136 | Loss = 2.510 | Accuracy = 32.188\n",
            "\u001b[32mVal: Epoch = 136 | Loss 2.679 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 137 | Loss = 2.563 | Accuracy = 28.438\n",
            "\u001b[32mVal: Epoch = 137 | Loss 2.678 | Accuracy = 27.586\n",
            "\u001b[30mTrain: Epoch = 138 | Loss = 2.461 | Accuracy = 32.500\n",
            "\u001b[32mVal: Epoch = 138 | Loss 2.677 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 139 | Loss = 2.499 | Accuracy = 34.688\n",
            "\u001b[32mVal: Epoch = 139 | Loss 2.676 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 140 | Loss = 2.477 | Accuracy = 34.688\n",
            "\u001b[32mVal: Epoch = 140 | Loss 2.675 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 141 | Loss = 2.547 | Accuracy = 27.500\n",
            "\u001b[32mVal: Epoch = 141 | Loss 2.675 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 142 | Loss = 2.462 | Accuracy = 34.375\n",
            "\u001b[32mVal: Epoch = 142 | Loss 2.673 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 143 | Loss = 2.506 | Accuracy = 31.250\n",
            "\u001b[32mVal: Epoch = 143 | Loss 2.670 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 144 | Loss = 2.508 | Accuracy = 32.812\n",
            "\u001b[32mVal: Epoch = 144 | Loss 2.669 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 145 | Loss = 2.414 | Accuracy = 38.750\n",
            "\u001b[32mVal: Epoch = 145 | Loss 2.670 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 146 | Loss = 2.463 | Accuracy = 34.688\n",
            "\u001b[32mVal: Epoch = 146 | Loss 2.669 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 147 | Loss = 2.556 | Accuracy = 32.500\n",
            "\u001b[32mVal: Epoch = 147 | Loss 2.669 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 148 | Loss = 2.474 | Accuracy = 31.875\n",
            "\u001b[32mVal: Epoch = 148 | Loss 2.670 | Accuracy = 28.448\n",
            "\u001b[30mTrain: Epoch = 149 | Loss = 2.496 | Accuracy = 33.125\n",
            "\u001b[32mVal: Epoch = 149 | Loss 2.671 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 150 | Loss = 2.563 | Accuracy = 33.438\n",
            "\u001b[32mVal: Epoch = 150 | Loss 2.673 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 151 | Loss = 2.473 | Accuracy = 34.062\n",
            "\u001b[32mVal: Epoch = 151 | Loss 2.673 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 152 | Loss = 2.449 | Accuracy = 34.062\n",
            "\u001b[32mVal: Epoch = 152 | Loss 2.673 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 153 | Loss = 2.408 | Accuracy = 35.938\n",
            "\u001b[32mVal: Epoch = 153 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 154 | Loss = 2.437 | Accuracy = 36.562\n",
            "\u001b[32mVal: Epoch = 154 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 155 | Loss = 2.446 | Accuracy = 36.875\n",
            "\u001b[32mVal: Epoch = 155 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 156 | Loss = 2.569 | Accuracy = 30.938\n",
            "\u001b[32mVal: Epoch = 156 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 157 | Loss = 2.475 | Accuracy = 32.812\n",
            "\u001b[32mVal: Epoch = 157 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 158 | Loss = 2.488 | Accuracy = 33.438\n",
            "\u001b[32mVal: Epoch = 158 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 159 | Loss = 2.487 | Accuracy = 34.688\n",
            "\u001b[32mVal: Epoch = 159 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 160 | Loss = 2.482 | Accuracy = 34.062\n",
            "\u001b[32mVal: Epoch = 160 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 161 | Loss = 2.553 | Accuracy = 30.000\n",
            "\u001b[32mVal: Epoch = 161 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 162 | Loss = 2.536 | Accuracy = 33.750\n",
            "\u001b[32mVal: Epoch = 162 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 163 | Loss = 2.610 | Accuracy = 31.875\n",
            "\u001b[32mVal: Epoch = 163 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 164 | Loss = 2.525 | Accuracy = 33.750\n",
            "\u001b[32mVal: Epoch = 164 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 165 | Loss = 2.588 | Accuracy = 32.188\n",
            "\u001b[32mVal: Epoch = 165 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 166 | Loss = 2.447 | Accuracy = 34.062\n",
            "\u001b[32mVal: Epoch = 166 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 167 | Loss = 2.414 | Accuracy = 36.250\n",
            "\u001b[32mVal: Epoch = 167 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 168 | Loss = 2.537 | Accuracy = 34.062\n",
            "\u001b[32mVal: Epoch = 168 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 169 | Loss = 2.490 | Accuracy = 30.938\n",
            "\u001b[32mVal: Epoch = 169 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 170 | Loss = 2.450 | Accuracy = 37.188\n",
            "\u001b[32mVal: Epoch = 170 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 171 | Loss = 2.468 | Accuracy = 31.250\n",
            "\u001b[32mVal: Epoch = 171 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 172 | Loss = 2.459 | Accuracy = 35.625\n",
            "\u001b[32mVal: Epoch = 172 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 173 | Loss = 2.454 | Accuracy = 34.688\n",
            "\u001b[32mVal: Epoch = 173 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 174 | Loss = 2.475 | Accuracy = 34.062\n",
            "\u001b[32mVal: Epoch = 174 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 175 | Loss = 2.447 | Accuracy = 35.312\n",
            "\u001b[32mVal: Epoch = 175 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 176 | Loss = 2.522 | Accuracy = 32.500\n",
            "\u001b[32mVal: Epoch = 176 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 177 | Loss = 2.531 | Accuracy = 30.312\n",
            "\u001b[32mVal: Epoch = 177 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 178 | Loss = 2.494 | Accuracy = 32.188\n",
            "\u001b[32mVal: Epoch = 178 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 179 | Loss = 2.496 | Accuracy = 34.375\n",
            "\u001b[32mVal: Epoch = 179 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 180 | Loss = 2.555 | Accuracy = 31.250\n",
            "\u001b[32mVal: Epoch = 180 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 181 | Loss = 2.482 | Accuracy = 35.000\n",
            "\u001b[32mVal: Epoch = 181 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 182 | Loss = 2.424 | Accuracy = 35.625\n",
            "\u001b[32mVal: Epoch = 182 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 183 | Loss = 2.473 | Accuracy = 31.562\n",
            "\u001b[32mVal: Epoch = 183 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 184 | Loss = 2.523 | Accuracy = 31.875\n",
            "\u001b[32mVal: Epoch = 184 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 185 | Loss = 2.491 | Accuracy = 36.875\n",
            "\u001b[32mVal: Epoch = 185 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 186 | Loss = 2.442 | Accuracy = 34.062\n",
            "\u001b[32mVal: Epoch = 186 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 187 | Loss = 2.475 | Accuracy = 34.375\n",
            "\u001b[32mVal: Epoch = 187 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 188 | Loss = 2.499 | Accuracy = 31.875\n",
            "\u001b[32mVal: Epoch = 188 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 189 | Loss = 2.500 | Accuracy = 35.312\n",
            "\u001b[32mVal: Epoch = 189 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 190 | Loss = 2.564 | Accuracy = 33.125\n",
            "\u001b[32mVal: Epoch = 190 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 191 | Loss = 2.557 | Accuracy = 30.625\n",
            "\u001b[32mVal: Epoch = 191 | Loss 2.675 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 192 | Loss = 2.345 | Accuracy = 36.875\n",
            "\u001b[32mVal: Epoch = 192 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 193 | Loss = 2.438 | Accuracy = 33.438\n",
            "\u001b[32mVal: Epoch = 193 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 194 | Loss = 2.514 | Accuracy = 34.375\n",
            "\u001b[32mVal: Epoch = 194 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 195 | Loss = 2.519 | Accuracy = 33.438\n",
            "\u001b[32mVal: Epoch = 195 | Loss 2.674 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 196 | Loss = 2.515 | Accuracy = 33.750\n",
            "\u001b[32mVal: Epoch = 196 | Loss 2.675 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 197 | Loss = 2.513 | Accuracy = 36.250\n",
            "\u001b[32mVal: Epoch = 197 | Loss 2.675 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 198 | Loss = 2.488 | Accuracy = 32.812\n",
            "\u001b[32mVal: Epoch = 198 | Loss 2.675 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 199 | Loss = 2.501 | Accuracy = 32.188\n",
            "\u001b[32mVal: Epoch = 199 | Loss 2.675 | Accuracy = 29.310\n",
            "\u001b[30mTrain: Epoch = 200 | Loss = 2.558 | Accuracy = 30.938\n",
            "\u001b[32mVal: Epoch = 200 | Loss 2.675 | Accuracy = 29.310\n",
            "\u001b[36mBest Acc -->  29.310344827586203\n",
            "\u001b[36mLast Acc -->  29.310344827586203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrLs_T2Qd0kc"
      },
      "source": [
        "#Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqK1ExB0cl8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a3e75e-3dd5-4628-b3b1-7a82b84a1197"
      },
      "source": [
        "model.train(False)\n",
        "val_loss_epoch = 0\n",
        "numCorr = 0\n",
        "val_iter = 0\n",
        "val_samples = len(test_dataset) \n",
        "val_steps = len(val_loader)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for j, (inputs, targets) in enumerate(val_loader):\n",
        "        val_iter += 1\n",
        "        inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "        labelVariable = targets.to(DEVICE)\n",
        "        \n",
        "        output_label, _ = model(inputVariable)\n",
        "        val_loss = loss_fn(output_label, labelVariable)\n",
        "        val_loss_step = val_loss.data.item()\n",
        "        val_loss_epoch += val_loss_step\n",
        "        _, predicted = torch.max(output_label.data, 1)\n",
        "        numCorr += torch.sum(predicted == labelVariable.data).data.item()\n",
        "        \n",
        "    val_accuracy = (numCorr / val_samples) * 100\n",
        "    avg_val_loss = val_loss_epoch / val_steps\n",
        "\n",
        "print('Loss {:.3f} | Accuracy = {:.3f}'.format(avg_val_loss, val_accuracy))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss 2.675 | Accuracy = 29.310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr9BxL8zeBfv"
      },
      "source": [
        "#**Learning with Temporal information** (LSTM)\n",
        "\n",
        "Loss 2.675 | Accuracy = 29.310"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-qHYgnyf_wn"
      },
      "source": [
        "#**Learning with Spatio-Temporal information** (ConvLSTM)\n",
        "\n",
        "Loss 1.947 | Accuracy = 45.690\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uRufVNHRBfjC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}